{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from utils import * \n",
    "from causalDataframe import *\n",
    "from causal_discovery.ncda import * \n",
    "from baselines.correlations import * \n",
    "from data_generation.randomDataframe import *\n",
    "from data_generation.relatedDataframe import * \n",
    "from data_generation.evaluation.kde import *\n",
    "from data_generation.evaluation.lof import *\n",
    "from sdv.tabular import CTGAN\n",
    "from sdv.tabular import TVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/martina/Desktop/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1# Option**: From sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A possible Ground Truth \n",
    "\n",
    "['bmi' --> 'si', 'bmi' --> 'bp', 'si' --> 'bp']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "dataframe = diabetes['data'][:, [0, 1, 2, 3, 4]]\n",
    "data = pd.DataFrame(dataframe, columns=['age', 'sex', 'bmi', 'bp', 'si'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2# Option**: From project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Avaiable datasets \n",
    "\n",
    "Abalone            Ground Truth: ['Rings' --> 'Length']\n",
    "Old Faithful       Ground Truth: ['Time Interval' --> 'Duration']\n",
    "Climate            Ground Truth: ['Altitude' --> 'Temperature']\n",
    "Undata             Ground Truth: ['Female Age' <-- 'Latitude']\n",
    "Synthetic          Ground Truth: ['w' --> 'x', 'w' --> 'y', 'x' --> 'z', 'y' --> z]\n",
    "\n",
    "\"\"\"\n",
    "directory = os.path.abspath('')\n",
    "file_path = os.path.join(os.path.dirname(directory), 'GENCDA', 'datasets', 'synthetic.csv')\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3# Option**: Create a new dataframe from a random DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph with 5 nodes and 2 edges\n",
    "# This function returns also a json file. It contains all the information about the dag.\n",
    "graph = randomDag(path, 4, 2)\n",
    "print(f'Nodes: {graph.nodes} \\nEdges: {graph.edges}')\n",
    "n_samples = 1500\n",
    "\n",
    "# Instantiate main class with the number of samples and the dag\n",
    "d = CausalDataFrame(n_samples, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a dataset based on the graph structure\n",
    "d.generate_data()\n",
    "# Get as a dataframe\n",
    "data = d.dataframe\n",
    "# Save the new dataframe\n",
    "data.to_csv(os.path.join(path, 'dataset.csv'), index=False)\n",
    "# Show the generated random dag\n",
    "d.show_graph()\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4# Option**: Create a new dataframe from a known graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [('0', '2'), ('1', '2'), ('2', '7'), ('1', '4'), ('4', '8')]\n",
    "isolated_nodes = ['3', '5', '6']\n",
    "n_samples = 1500\n",
    "\n",
    "# Instantiate main class with the number of samples and the dag\n",
    "d = CausalDataFrame(n_samples, edges, isolated_nodes)\n",
    "# Generate a dataset based on the graph structure\n",
    "d.generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get as a dataframe\n",
    "data = d.dataframe\n",
    "# Save the new dataframe\n",
    "data.to_csv(os.path.join(path, 'dataset.csv'), index=False)\n",
    "# Show the generated random dag\n",
    "d.show_graph()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAG DESCRIBING THE CAUSAL STRUCTURE OF THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1# Option**: Based on a known ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: Synthetic Dataset\n",
    "\n",
    "\"\"\"\n",
    "graph = nx.DiGraph()\n",
    "graph.add_nodes_from(['w', 'y', 'x', 'z'])\n",
    "graph.add_edges_from([('w', 'x'), ('w', 'y'), ('x', 'z'), ('y', 'z')])\n",
    "nx.draw_networkx(graph, node_size=1500, font_color='w', font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2# Option**: From a random graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = randomDag(path, 6, 4)\n",
    "nx.draw_networkx(graph, node_size=1500, font_color='w', font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCDA - Nonlinear Causal Discovery with Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate main class\n",
    "ncda = NCDApriori(data, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Apriori \n",
    "\n",
    "\"\"\"\n",
    "Since our method works on continuos dataset, we discretize our dataframe to apply the pattern mining algorithm. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "itemsets, performance = ncda.fitApriori(target='m', zmax=3, nbins=4, strategy='quantile', support=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Maximal itemsets found by Apriori: \\n\\n{itemsets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation of the number of relations found comparing frequent items found by apriori and the dag. \n",
    "In this case, we verify relations on an undirect acyclic graph \n",
    "since we want to know if apriori detects any relationship. Then, edges directions are not relevant.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Causal Discovery Algorithm implemented by Hoyer et al.\n",
    "\n",
    "causal_relations = ncda.fitNCD(itemsets, alpha=0.001, sorting=np.mean, train_size=0.7, standardization=True)\n",
    "causal_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation of the number of relations found comparing causal relationship found by NCD and the ground truth. \n",
    "In this case, we verify relations on an direct acyclic graph.\n",
    "\"\"\" \n",
    "\n",
    "# We have to transform dag edges as strings\n",
    "edges = [(str(source), str(destination)) for source, destination in graph.edges]\n",
    "\n",
    "precision, recall, accuracy, f1 = evaluate(causal_relations, edges, graph)\n",
    "print(f'Precision: {precision}\\nRecall: {recall}\\nAccuracy: {accuracy}\\nF1: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAUSAL DISCOVERY BASELINES: CORRELATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibile correlation coefficients to check: Pearson, Spearman, Hoeffding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main class\n",
    "corr = Correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute test statistic **between two variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p_value = corr.pearson(data.iloc[:, 0], data.iloc[:, 1])\n",
    "r, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute **pairwise correlation of columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = corr.pairwise(data, pearsonr)\n",
    "columns, confusion_matrix = corr.evaluate(new_df, graph)\n",
    "print(f'List of indices of column pairs that are correlated: {columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation of the number of relations found comparing relations found by correlation metric and the ground truth. \n",
    "In this case, we verify relations on an undirect acyclic graph.\n",
    "\n",
    "\"\"\"\n",
    "precision, recall, accuracy, f1 = evaluation_measures(confusion_matrix)\n",
    "print(f'Precision: {precision}\\nRecall: {recall}\\nAccuracy: {accuracy}\\nF1: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNTHETIC DATA GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A synthetic dataset generator for tabular data that is able to discover the nonlinear causalities \n",
    "among the variables and use them at generation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a DAG from causal relationships founded by NCDA\n",
    "dag_ncda = nx.to_networkx_graph(causal_relations, create_using=nx.DiGraph)\n",
    "\n",
    "# Add isolated nodes. We select them from dataset columns\n",
    "dag_nodes = list(data.columns)\n",
    "dag_ncda.add_nodes_from(dag_nodes)\n",
    "\n",
    "nx.draw_networkx(dag_ncda, node_size=1500, font_color='w', font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate main class\n",
    "generator = RelatedDataframe(data, dag_ncda)\n",
    "\n",
    "# Generate new data based on ground truth dag \n",
    "gencda_data = generator.generate_data()\n",
    "\n",
    "# Show new dataframe \n",
    "gencda_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNTHETIC DATA GENERATION BASELINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1# Baseline: **RANDOM GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = randomDataframe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2# Baseline: **CTGAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From Synthetic Data Vault Library (SDV)\n",
    "https://sdv.dev/SDV/api_reference/tabular/api/sdv.tabular.ctgan.CTGAN.html\n",
    "\n",
    "\"\"\"\n",
    "# Instantiate main class\n",
    "model = CTGAN()\n",
    "\n",
    "# Fit CTGAN\n",
    "model.fit(data)\n",
    "\n",
    "# Save model\n",
    "model.save(os.path.join(path, 'ctgan_model.pkl'))\n",
    "\n",
    "# Generate new data\n",
    "ctgan_data = model.sample(len(data))\n",
    "\n",
    "# Save new dataframe \n",
    "ctgan_data.to_csv(os.path.join(path, 'ctgan_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3# Baseline: **TVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From SDV Library \n",
    "https://sdv.dev/SDV/api_reference/tabular/api/sdv.tabular.ctgan.TVAE.html\n",
    "\n",
    "\"\"\"\n",
    "# To apply tvae, the svd library requires columns names as strings \n",
    "if data.columns.dtype != 'str':\n",
    "    data.columns = data.columns.astype(str)\n",
    "\n",
    "# Instantiate main class\n",
    "model = TVAE()\n",
    "\n",
    "# Fit TVAE\n",
    "model.fit(data)\n",
    "\n",
    "# Save model\n",
    "model.save(os.path.join(path, 'tvae_model.pkl'))\n",
    "\n",
    "# Generate new data\n",
    "tvae_data = model.sample(len(data))\n",
    "\n",
    "# Save new dataframe \n",
    "tvae_data.to_csv(os.path.join(path, 'tvae_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION MEASURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Compute SSE, RMSE using KERNEL DENSITY ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GENDATA {get_statistics(data, gencda_data)}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'RANDOM {get_statistics(data, random_data)}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'CTGAN {get_statistics(data, ctgan_data)}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'TVAE {get_statistics(data, tvae_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GENDATA {lof(data, gencda_data, n_neighbors=50)}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'RANDOM {lof(data, random_data, n_neighbors=50)}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'CTGAN {lof(data, ctgan_data, n_neighbors=50)}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'TVAE {lof(data, tvae_data, n_neighbors=50)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of column to plot\n",
    "index = 0\n",
    "\n",
    "datasets = [gencda_data, random_data, ctgan_data, tvae_data]\n",
    "names = ['GENCDA', 'RANDOM', 'CTGAN', 'TVAE']\n",
    "\n",
    "for dataset, name in zip(datasets, names):\n",
    "    plotKDE(data.iloc[:, index], dataset.iloc[:, index], label1='Original Data', label2=name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set index of column to plot\n",
    "index = [0, 1]\n",
    "\n",
    "datasets = [gencda_data, random_data, ctgan_data, tvae_data]\n",
    "names = ['GENCDA', 'RANDOM', 'CTGAN', 'TVAE']\n",
    "\n",
    "for dataset in [gencda_data, random_data, ctgan_data, tvae_data]:\n",
    "    plotLOF(data.iloc[:, index], dataset.iloc[:, index])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}